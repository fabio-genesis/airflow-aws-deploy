[api]
auth_backend = airflow.api.auth.backend.basic_auth

[core]
executor = CeleryExecutor
dags_are_paused_at_creation = True
load_examples = True
load_default_connections = False

[webserver]
dag_default_view = graph
expose_config = True
reload_on_plugin_change = True
dag_orientation = TB

[metrics]
# The airflow scheduler sends statsd metrics over UDP to port 8125.
# https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/logging-architecture.html
# You can verify this by setting the statsd_host to localhost or 0.0.0.0 and listening via netcat.
#   Eg. docker compose exec airflow-scheduler nc -l -u -p 8125 127.0.0.1
statsd_on = True
statsd_host = statsd-exporter
statsd_port = 8125
statsd_prefix = airflow

[scheduler]
catchup_by_default = False

[logging]
logging_config_class = deploy_airflow_on_ecs_fargate.logging_config.STDOUT_LOGGING_CONFIG

# Not working
# [secrets]
# Local Filesystem Secrets Backend
# https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/local-filesystem-secrets-backend.html
# backend = airflow.secrets.local_filesystem.LocalFilesystemBackend
# backend_kwargs = {"variables_file_path": "/opt/airflow/secrets/var.yaml", "connections_file_path": "/opt/airflow/secrets/conn.yaml"}
