# airflow-on-ecs-fargate
Um exemplo de como implantar o [Apache Airflow](https://github.com/apache/airflow) no Amazon ECS Fargate.

#### √çndice
- [Resumo](#resumo)  
  - [Estrutura do projeto](#estrutura-do-projeto)  
- [Primeiros passos](#primeiros-passos)  
  - [‚öôÔ∏è Ambiente de desenvolvimento local (opcional)](#Ô∏è-ambiente-de-desenvolvimento-local-opcional)  
  - [üöÄ Configurar um cluster ECS (produ√ß√£o)](#-configurar-um-cluster-ecs-produ√ß√£o)  
- [Tarefas independentes](#tarefas-independentes)  
- [Logs](#logs)  
- [Custo](#custo)  
- [Autoescalonamento](#autoescalonamento)  
- [Exemplos](#exemplos)  
  - [Executar um comando arbitr√°rio como tarefa independente](#executar-um-comando-arbitr√°rio-como-tarefa-independente)  
  - [Abrir um shell em um cont√™iner de servi√ßo usando ECS exec](#abrir-um-shell-em-um-cont√™iner-de-servi√ßo-usando-ecs-exec)  
  - [Escalonar manualmente um servi√ßo para zero](#escalonar-manualmente-um-servi√ßo-para-zero)  

---

## Resumo

O objetivo deste projeto √© demonstrar como implantar o [Apache Airflow](https://github.com/apache/airflow) no AWS Elastic Container Service usando o provedor de capacidade Fargate. O c√≥digo deste reposit√≥rio serve como exemplo para ajudar desenvolvedores a criarem sua pr√≥pria configura√ß√£o. No entanto, √© poss√≠vel implant√°-lo seguindo as etapas descritas em [Configurar um cluster ECS](#-configurar-um-cluster-ecs-produ√ß√£o).

O Airflow e o ECS possuem muitos recursos e op√ß√µes de configura√ß√£o. Este projeto cobre v√°rios casos de uso, por exemplo:  
- Autoescalar workers at√© zero  
- Redirecionar logs do servi√ßo Airflow para o CloudWatch e para o Kinesis Firehose usando [fluentbit](https://fluentbit.io/)  
- Usar [remote_logging](https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/logging-tasks.html#logging-for-tasks) para enviar/receber logs de workers para/de S3  
- Usar o provedor AWS [SecretsManagerBackend](https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/secrets-backends/aws-secrets-manager.html) para armazenar/consumir configura√ß√µes sens√≠veis no [SecretsManager](https://aws.amazon.com/secrets-manager/)  
- Executar um comando √∫nico como tarefa ECS independente (ex.: `airflow db init`)  
- Abrir um shell em um cont√™iner em execu√ß√£o via ECS exec  
- Enviar m√©tricas statsd do Airflow para o CloudWatch  

Esses exemplos de configura√ß√£o s√£o √∫teis mesmo para quem n√£o executa Airflow no ECS.

---

### Estrutura do projeto

```
‚îú‚îÄ‚îÄ build .............................. tudo relacionado √† constru√ß√£o de imagens de cont√™iner
‚îÇ   ‚îú‚îÄ‚îÄ dev ............................ config de desenvolvimento referenciada no docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ prod ........................... config de produ√ß√£o usada para construir a imagem enviada ao ECR
‚îú‚îÄ‚îÄ dags ............................... diret√≥rio AIRFLOW_HOME/dags
‚îú‚îÄ‚îÄ deploy_airflow_on_ecs_fargate ...... pacote python import√°vel de dags/plugins usado para configs extras
‚îÇ   ‚îú‚îÄ‚îÄ celery_config.py ............... configura√ß√£o customizada do celery
‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py .............. configura√ß√£o customizada de logs
‚îú‚îÄ‚îÄ docker-compose.yml ................. config de build para ambiente de desenvolvimento
‚îú‚îÄ‚îÄ infrastructure ..................... configura√ß√£o ECS com terraform
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfvars.template ...... template para vari√°veis sens√≠veis necess√°rias ao deploy
‚îÇ   ‚îî‚îÄ‚îÄ *.tf ........................... exemplo de configura√ß√£o do cluster ECS
‚îú‚îÄ‚îÄ plugins ............................ diret√≥rio AIRFLOW_HOME/plugins
‚îî‚îÄ‚îÄ scripts
    ‚îú‚îÄ‚îÄ put_airflow_worker_xxx.py ...... envia m√©tricas de autoescalonamento customizadas ao CloudWatch
    ‚îî‚îÄ‚îÄ run_task.py .................... exemplo de script python para executar tarefas independentes no cluster ECS
```

---

## Primeiros passos

### ‚öôÔ∏è Ambiente de desenvolvimento local (opcional)

> Esta se√ß√£o √© **apenas para desenvolvimento/testes locais** usando Docker Compose.  
> Se o seu objetivo √© implantar diretamente em **produ√ß√£o no ECS Fargate**, pule para [üöÄ Configurar um cluster ECS (produ√ß√£o)](#-configurar-um-cluster-ecs-produ√ß√£o).

1. Inicializar o banco de metadados  
```shell
docker compose run --rm airflow-cli db init
```

2. Criar um usu√°rio admin  
```shell
docker compose run --rm airflow-cli users create --email airflow@example.com --firstname airflow --lastname airflow --password airflow --username airflow --role Admin
```

3. Iniciar todos os servi√ßos  
```shell
docker compose up -d
```

---

### üöÄ Configurar um cluster ECS (produ√ß√£o)

> A partir daqui, come√ßa a configura√ß√£o do ambiente em **produ√ß√£o**, implantando o Airflow no Amazon ECS Fargate com Terraform e ECR.  

1. Inicializar diret√≥rio terraform  
```shell
terraform -chdir=infrastructure init
```

2. (Opcional) Criar arquivo `terraform.tfvars` e definir vari√°veis `aws_region`, `metadata_db` e `fernet_key`  
```shell
cp infrastructure/terraform.tfvars.template infrastructure/terraform.tfvars
```

3. Criar reposit√≥rio ECR para armazenar a imagem customizada do Airflow  
```shell
terraform -chdir=infrastructure apply -target=aws_ecr_repository.airflow
```

4. Obter URI do reposit√≥rio via `awscli` ou [console AWS](https://console.aws.amazon.com/ecr/repositories)  
```shell
aws ecr describe-repositories
```

5. Autenticar Docker/Podman no ECR  
```shell
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ***.dkr.ecr.us-east-1.amazonaws.com
```

6. Construir e enviar a imagem do cont√™iner  
```shell
export REPO_URI="***.dkr.ecr.us-east-1.amazonaws.com/deploy-airflow-on-ecs-fargate-airflow"
docker buildx build -t "${REPO_URI}" -f build/prod/Containerfile --platform linux/amd64 .
docker push "${REPO_URI}"
```

7. Implantar a infraestrutura restante  
```shell
terraform -chdir=infrastructure apply
```

8. Inicializar o banco de metadados do Airflow como tarefa ECS independente  
```shell
python3 scripts/run_task.py --wait-tasks-stopped --command 'db init'
```

9. Criar um usu√°rio admin do mesmo modo  
```shell
python3 scripts/run_task.py --wait-tasks-stopped --command   'users create --username airflow --firstname airflow --lastname airflow --password airflow --email airflow@example.com --role Admin'
```

10. Obter e abrir a URI do Load Balancer do webserver  
```shell
aws elbv2 describe-load-balancers
```
